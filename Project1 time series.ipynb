{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Monthly Armed Robberies in Boston\n",
    "\n",
    "Author: Jason Brownlee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work through a **time series forecasting project from end-to-end**, from\n",
    "downloading the dataset and defining the problem to training a final model and making\n",
    "predictions. This project is not exhaustive, but **shows how you can get good results quickly by\n",
    "working through a time series forecasting problem systematically**. The steps of this project that\n",
    "we will work through are as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Problem Description.\n",
    "2. Test Harness.\n",
    "3. Persistence.\n",
    "4. Data Analysis.\n",
    "5. ARIMA Models.\n",
    "6. Model Validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset\n",
    "provides the number of monthly armed robberies in Boston from January 1966 to October 1975,\n",
    "or just under 10 years of data. The values are a count and there are 118 observations. The\n",
    "dataset is credited to McCleary and Hay (1980)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Harness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must develop a test harness to investigate the data and evaluate candidate models. This\n",
    "involves two steps:\n",
    "\n",
    "1. Defining a Validation Dataset.\n",
    "2. Developing a Method for Model Evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is not current. This means that **we cannot easily collect updated data to validate\n",
    "the model**. Therefore we will pretend that it is October 1974 and withhold **the last one year of\n",
    "data from analysis and model selection**. This final year of data will be used to validate the final\n",
    "model. The code below will load the dataset as a Pandas Series and split into two, one for\n",
    "model development (dataset.csv) and the other for validation (validation.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# split into a training and validation dataset\n",
    "from pandas import read_csv\n",
    "\n",
    "series = read_csv(\n",
    "    \"robberies.csv\", header=0, index_col=0, parse_dates=True, squeeze=True\n",
    ")\n",
    "split_point = len(series) - 12\n",
    "dataset, validation = series[0:split_point], series[split_point:]\n",
    "print(\"Dataset %d, Validation %d\" % (len(dataset), len(validation)))\n",
    "dataset.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "len(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "split_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "validation.to_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates two files and prints the number of observations in each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific contents of these files are:\n",
    "\n",
    "- dataset.csv: Observations from January 1966 to October 1974 (106 observations)\n",
    "- validation.csv: Observations from November 1974 to October 1975 (12 observations)\n",
    "\n",
    "The validation dataset is 10% of the original dataset. Note that the saved datasets do not\n",
    "have a header line, therefore we do not need to cater to this when working with these files later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation will only be performed on the data in dataset.csv prepared in the previous\n",
    "section. Model evaluation involves two elements:\n",
    "\n",
    "1. Performance Measure.\n",
    "2. Test Strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance Measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations are a count of robberies. We will evaluate the performance of predictions using\n",
    "the root mean squared error **(RMSE)**. This will give **more weight to predictions that are grossly\n",
    "wrong** and will have the same units as the original data. Any transforms to the data must be\n",
    "reversed before the RMSE is calculated and reported to make the performance between different\n",
    "methods directly comparable.\n",
    "\n",
    "We can calculate the RMSE using the helper function from the scikit-learn library mean squared error()\n",
    "\n",
    "that calculates the mean squared error between a list of expected values (the test set) and the\n",
    "list of predictions. We can then take the square root of this value to give us an RMSE score.\n",
    "For example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# ...\n",
    "# test = ...\n",
    "# predictions = ...\n",
    "# mse = mean_squared_error(test, predictions)\n",
    "# rmse = sqrt(mse)\n",
    "# print('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Candidate models will be evaluated using walk-forward validation**. This is because a rolling forecast type model is required from the problem definition. This is where one-step forecasts\n",
    "are needed given all available data. The walk-forward validation will work as follows:\n",
    "\n",
    "1. The first 50% of the dataset will be held back to train the model.\n",
    "2. The remaining 50% of the dataset will be iterated and test the model.\n",
    "3. For each step in the test dataset:\n",
    "\n",
    "   (a) A model will be trained.\n",
    "\n",
    "   (b) A one-step prediction made and the prediction stored for later evaluation.\n",
    "\n",
    "   (c) The actual observation from the test dataset will be added to the training dataset for the next iteration.\n",
    "\n",
    "The predictions made during the iteration of the test dataset will be evaluated and an RMSE score reported.\n",
    "\n",
    "Given the small size of the data, we will allow a model to be re-trained given all available\n",
    "data prior to each prediction. We can write the code for the test harness using simple NumPy\n",
    "and Python code. Firstly, we can split the dataset into train and test sets directly. We’re careful\n",
    "to always convert a loaded dataset to float32 in case the loaded data still has some String or\n",
    "Integer data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype(\"float32\")\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, **we can iterate over the time steps in the test dataset**. The train dataset is stored in a\n",
    "Python list as we need to easily append a new observation each iteration and NumPy array\n",
    "concatenation feels like overkill. The prediction made by the model is called yhat for convention,\n",
    "as the outcome or observation is referred to as **y and yhat (a y with a mark above)** is the\n",
    "mathematical notation for the prediction of the y variable. The prediction and observation are\n",
    "printed each observation for a sanity check prediction in case there are issues with the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# walk-forward validation\n",
    "# history = [x for x in train]\n",
    "# predictions = list()\n",
    "# for i in range(len(test)):\n",
    "# predict\n",
    "# yhat = ...\n",
    "# predictions.append(yhat)\n",
    "# observation\n",
    "# obs = test[i]\n",
    "# history.append(obs)\n",
    "# print('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Persistence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The first step** before getting bogged down in data analysis and modeling **is to establish a baseline\n",
    "of performance**. This will provide both a template for evaluating models using the proposed\n",
    "test harness and a performance measure by which all more elaborate predictive models can be\n",
    "compared. **The baseline prediction for time series forecasting is called the naive forecast**, or\n",
    "persistence. This is where the observation from the previous time step is used as the prediction\n",
    "for the observation at the next time step. We can plug this directly into the test harness defined\n",
    "in the previous section. The complete code listing is provided below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "    # predict\n",
    "    yhat = history[-1]\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "    print(\">Predicted=%.3f, Expected=%3.f\" % (yhat, obs))\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the test harness prints the prediction and observation for each iteration of the test\n",
    "dataset. The example ends by printing the RMSE for the model. In this case, we can see that\n",
    "the persistence model achieved an RMSE of 54.191. This means that on average, the model was\n",
    "wrong by about 54 robberies for each prediction made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a baseline prediction method and performance; now we can start digging into\n",
    "our data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use summary statistics and plots of the data to quickly learn more about the structure\n",
    "of the prediction problem. In this section, we will look at the data from four perspectives:\n",
    "\n",
    "1. Summary Statistics.\n",
    "2. Line Plot.\n",
    "3. Density Plots.\n",
    "4. Box and Whisker Plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics\n",
    "\n",
    "Open the data dataset.csv file and/or the original robberies.csv file in a text editor and\n",
    "look at the data. A quick check suggests that there are no obviously missing observations.\n",
    "We may have noticed this earlier if we tried to force the series to floating point values and\n",
    "values like NaN or ? were in the data. Summary statistics provide a quick look at the limits of\n",
    "observed values. It can help to get a quick idea of what we are working with. The example\n",
    "below calculates and prints summary statistics for the time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example provides a number of summary statistics to review. Some observations\n",
    "from these statistics include:\n",
    "\n",
    "- The number of observations (count) matches our expectation, meaning we are handling\n",
    "  the data correctly.\n",
    "- The mean is about 173, which we might consider our level in this series.\n",
    "- The standard deviation (average spread from the mean) is relatively large at 112 robberies.\n",
    "- The percentiles along with the standard deviation do suggest a large spread to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The large spread in this series will likely make highly accurate predictions difficult if it is\n",
    "caused by random fluctuation (e.g. not systematic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A line plot of a time series can provide a lot of insight into the problem. The example below\n",
    "creates and shows a line plot of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# line plots of time series\n",
    "from matplotlib import pyplot\n",
    "\n",
    "dataset.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the example and review the plot. Note any obvious temporal structures in the series.\n",
    "Some observations from the plot include:\n",
    "\n",
    "- There is an increasing trend of robberies over time.\n",
    "- There do not appear to be any obvious outliers.\n",
    "- There are relatively large fluctuations from year to year, up and down.\n",
    "- The fluctuations at later years appear larger than fluctuations at earlier years.\n",
    "- The trend means the dataset is almost certainly non-stationary and the apparent change\n",
    "  in fluctuation may also contribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These simple observations suggest we may see benefit in modeling the trend and removing\n",
    "it from the time series. Alternately, we could use differencing to make the series stationary\n",
    "for modeling. We may even need two levels of differencing if there is a growth trend in the\n",
    "fluctuations in later years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing plots of the density of observations can provide further insight into the structure of\n",
    "the data. The example below creates a histogram and density plot of the observations without\n",
    "any temporal structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pyplot.figure(1)\n",
    "pyplot.subplot(211)\n",
    "dataset.hist()\n",
    "pyplot.subplot(212)\n",
    "dataset.plot(kind=\"kde\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the example and review the plots. Some observations from the plots include:\n",
    "\n",
    "- The distribution is not Gaussian.\n",
    "- The distribution is left shifted and may be exponential or a double Gaussian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box and Whisker Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group the monthly data by year and get an idea of the spread of observations for each\n",
    "year and how this may be changing. We do expect to see some trend (increasing mean or\n",
    "median), but it may be interesting to see how the rest of the distribution may be changing. The\n",
    "example below groups the observations by year and creates one box and whisker plot for each\n",
    "year of observations. The last year (1974) only contains 10 months and may not be a useful\n",
    "comparison with the other 12 months of observations in the other years. Therefore only data\n",
    "between 1966 and 1973 was plotted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pandas import Grouper\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "groups = dataset[\"1966\":\"1973\"].groupby(Grouper(freq=\"A\"))\n",
    "years = DataFrame()\n",
    "for name, group in groups:\n",
    "    years[name.year] = group.values\n",
    "years.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates 8 box and whisker plots side-by-side, one for each of the 8\n",
    "years of selected data. Some observations from reviewing the plot include:\n",
    "\n",
    "- The median values for each year (red line) show a trend that may not be linear.\n",
    "- The spread, or middle 50% of the data (blue boxes), differ, but perhaps not consistently\n",
    "  over time.\n",
    "- The earlier years, perhaps first 2, are quite different from the rest of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations suggest that the year-to-year fluctuations may not be systematic and hard\n",
    "to model. They also suggest that there may be some benefit in clipping the first two years of\n",
    "data from modeling if it is indeed quite different. This yearly view of the data is an interesting\n",
    "avenue and could be pursued further by looking at summary statistics from year-to-year and\n",
    "changes in summary stats from year-to-year. Next, we can start looking at predictive models of\n",
    "the series.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will develop Autoregressive Integrated Moving Average, or ARIMA, models\n",
    "for the problem. We will approach this in four steps:\n",
    "\n",
    "1. Developing a manually configured ARIMA model.\n",
    "2. Using a grid search of ARIMA to find an optimized model.\n",
    "3. Analysis of forecast residual errors to evaluate any bias in the model.\n",
    "4. Explore improvements to the model using power transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Configured ARIMA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonseasonal ARIMA(p,d,q) requires three parameters and is traditionally configured manually.\n",
    "Analysis of the time series data assumes that we are working with a stationary time series. The\n",
    "time series is almost certainly non-stationary. We can make it stationary by first differencing\n",
    "the series and using a statistical test to confirm that the result is stationary. The example below\n",
    "creates a stationary version of the series and saves it to file stationary.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# statistical test for the stationarity of the time series\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "\n",
    "# create a differenced time series\n",
    "def difference(dataset):\n",
    "    diff = list()\n",
    "    for i in range(1, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - 1]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "\n",
    "X = dataset.values\n",
    "# difference data\n",
    "stationary = difference(X)\n",
    "stationary.index = dataset.index[1:]\n",
    "\n",
    "# check if stationary\n",
    "result = adfuller(stationary)\n",
    "print(\"ADF Statistic: %f\" % result[0])\n",
    "print(\"p-value: %f\" % result[1])\n",
    "print(\"Critical Values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value))\n",
    "# save\n",
    "stationary.to_csv(\"stationary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example outputs the result of a statistical significance test of whether the 1-lag\n",
    "differenced series is stationary. Specifically, the augmented Dickey-Fuller test. The results show\n",
    "that the test statistic value -3.980946 is smaller than the critical value at 5% of -2.893. This\n",
    "suggests that we can reject the null hypothesis with a significance level of less than 5% (i.e. a\n",
    "low probability that the result is a statistical fluke). Rejecting the null hypothesis means that\n",
    "the process has no unit root, and in turn that the 1-lag differenced time series is stationary or\n",
    "does not have time-dependent structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that at least one level of differencing is required. The d parameter in our\n",
    "ARIMA model should at least be a value of 1. The next step is to select the lag values for\n",
    "the Autoregression (AR) and Moving Average (MA) parameters, p and q respectively. We can\n",
    "do this by reviewing Autocorrelation Function (ACF) and Partial Autocorrelation Function\n",
    "(PACF) plots. The example below creates ACF and PACF plots for the series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "plot_acf(dataset, lags=50, ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "plot_pacf(dataset, lags=50, ax=pyplot.gca())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the example and review the plots for insights into how to set the p and q variables for\n",
    "the ARIMA model. Below are some observations from the plots.\n",
    "\n",
    "- The ACF shows a significant lag for 10-11 months.\n",
    "- The PACF shows a significant lag for perhaps 2 months.\n",
    "- Both the ACF and PACF show a drop-off at the same point, perhaps suggesting a mix of AR and MA.\n",
    "\n",
    "A good starting point for the p and q values is 1 or 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quick analysis suggests an ARIMA(2,1,10) on the raw data may be a good starting\n",
    "point. Experimentation shows that this configuration of ARIMA does not converge and results\n",
    "in errors by the underlying library, as do similarly large AR values. **Some experimentation shows\n",
    "that the model does not appear to be stable**, with non-zero AR and MA orders defined at the\n",
    "same time. **The model can be simplified to ARIMA(0,1,2)**. The example below demonstrates\n",
    "the performance of this ARIMA model on the test harness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # predict\n",
    "    model = ARIMA(history, order=(0, 1, 2))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "    print(\">Predicted=%.3f, Expected=%3.f\" % (yhat, obs))\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example results in an RMSE of 51.007, which is lower than the persistence\n",
    "model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start, but we may be able to get improved results with a better configured\n",
    "ARIMA model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search ARIMA Hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many ARIMA configurations are unstable on this dataset, but there may be other hyperparameters that result in a well-performing model. In this section, we will search values of p, d, and q\n",
    "for combinations that do not result in error, and find the combination that results in the best\n",
    "performance. We will use a grid search to explore all combinations in a subset of integer values.\n",
    "Specifically, we will search all combinations of the following parameters:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p: 0 to 12\n",
    "- d: 0 to 3\n",
    "- q: 0 to 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is (13 × 4 × 13), or 676, runs of the test harness and will take some time to execute.\n",
    "The complete worked example with the grid search version of the test harness is listed below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas import read_csv\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "    # prepare training dataset\n",
    "    X = X.astype(\"float32\")\n",
    "    train_size = int(len(X) * 0.50)\n",
    "    train, test = X[0:train_size], X[train_size:]\n",
    "    history = [x for x in train]\n",
    "    # make predictions\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        predictions.append(yhat)\n",
    "        history.append(test[t])\n",
    "\n",
    "    # calculate out of sample error\n",
    "    rmse = sqrt(mean_squared_error(test, predictions))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "\n",
    "\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "    dataset = dataset.astype(\"float32\")\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p, d, q)\n",
    "                try:\n",
    "                    rmse = evaluate_arima_model(dataset, order)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, order\n",
    "                    print(\"ARIMA%s RMSE=%.3f\" % (order, rmse))\n",
    "                except:\n",
    "                    continue\n",
    "    print(\"Best ARIMA%s RMSE=%.3f\" % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "# evaluate parameters\n",
    "p_values = range(0, 13)\n",
    "d_values = range(0, 4)\n",
    "q_values = range(0, 13)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(dataset.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "Image(filename=\"ARIMA1result.png\", width=300, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "Image(filename=\"BestARIMA.png\", width=300, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Residual Errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good final check of a model is to review residual forecast errors. Ideally, the distribution\n",
    "of residual errors should be a Gaussian with a zero mean. We can check this by plotting the\n",
    "residuals with a histogram and density plots. The example below calculates the residual errors\n",
    "for predictions on the test set and creates these density plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# plot residual errors for ARIMA model\n",
    "\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# prepare data\n",
    "X = dataset.values\n",
    "X = X.astype(\"float32\")\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "\n",
    "for i in range(len(test)):\n",
    "    # predict\n",
    "    model = ARIMA(history, order=(0, 1, 2))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "\n",
    "# errors\n",
    "residuals = [test[i] - predictions[i] for i in range(len(test))]\n",
    "residuals = DataFrame(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "residuals.hist(ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "residuals.plot(kind=\"kde\", ax=pyplot.gca())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates the two plots. The graphs suggest a Gaussian-like distribution\n",
    "with a longer right tail. This is perhaps a sign that the predictions are biased, and in this case\n",
    "that perhaps a power-based transform of the raw data before modeling might be useful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also a good idea to check the time series of the residual errors for any type of autocorrelation. If present, it would suggest that the model has more opportunity to model the temporal\n",
    "structure in the data. The example below re-calculates the residual errors and creates ACF and\n",
    "PACF plots to check for any significant autocorrelation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "pyplot.figure()\n",
    "pyplot.subplot(211)\n",
    "plot_acf(residuals, lags=25, ax=pyplot.gca())\n",
    "pyplot.subplot(212)\n",
    "plot_pacf(residuals, lags=25, ax=pyplot.gca())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results suggest that what little autocorrelation is present in the time series has been\n",
    "captured by the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Cox Transformed Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Box-Cox transform is a method that is able to evaluate a suite of power transforms,\n",
    "including, but not limited to, log, square root, and reciprocal transforms of the data. The\n",
    "example below performs a log transform of the data and generates some plots to review the\n",
    "effect on the time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import boxcox\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "X = dataset.values\n",
    "transformed, lam = boxcox(X)\n",
    "print(\"Lambda: %f\" % lam)\n",
    "pyplot.figure(1)\n",
    "# line plot\n",
    "pyplot.subplot(311)\n",
    "pyplot.plot(transformed)\n",
    "# histogram\n",
    "pyplot.subplot(312)\n",
    "pyplot.hist(transformed)\n",
    "# q-q plot\n",
    "pyplot.subplot(313)\n",
    "qqplot(transformed, line=\"r\", ax=pyplot.gca())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates three graphs: a line chart of the transformed time series, a\n",
    "histogram showing the distribution of transformed values, and a Q-Q plot showing how the\n",
    "distribution of values compared to an idealized Gaussian distribution. Some observations from\n",
    "these plots are follows:\n",
    "\n",
    "- The large fluctuations have been removed from the line plot of the time series.\n",
    "- The histogram shows a flatter or more uniform (well behaved) distribution of values.\n",
    "- The Q-Q plot is reasonable, but still not a perfect fit for a Gaussian distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undoubtedly, the Box-Cox transform has done something to the time series and may be\n",
    "useful. Before proceeding to test the ARIMA model with the transformed data, we must have\n",
    "a way to reverse the transform in order to convert predictions made with a model trained on\n",
    "the transformed data back into the original scale. The boxcox() function used in the example\n",
    "finds an ideal lambda value by optimizing a cost function. The lambda is used in the following function to transform the data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$transform = log(x)$, If $lambda = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$transform =  \\frac{x^{\\lambda}-1}{\\lambda}$, IF $\\lambda \\neq 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transform function can be reversed directly, as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x = \\exp(transform)$, IF $\\lambda = 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x = \\exp \\left( \\frac{(log(\\lambda \\times transform + 1)} {\\lambda}\\right)$, IF $\\lambda \\neq 0 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "\n",
    "# invert box-cox transform\n",
    "def boxcox_inverse(value, lam):\n",
    "    if lam == 0:\n",
    "        return exp(value)\n",
    "    return exp(log(lam * value + 1) / lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-evaluate the ARIMA(0,1,2) model with the Box-Cox transform. This involves\n",
    "first transforming the history prior to fitting the ARIMA model, then inverting the transform\n",
    "on the prediction before storing it for later comparison with the expected values. **The boxcox()\n",
    "function can fail**. In practice, It has been seen this and it appears to be signaled by a returned\n",
    "lambda value of less than -5. By convention, **lambda values are evaluated between -5 and 5**.\n",
    "A check is added for a lambda value less than -5, and if this the case, a lambda value of 1\n",
    "is assumed and the raw history is used to fit the model. **A lambda value of 1 is the same as\n",
    "no-transform** and therefore the inverse transform has no effect. The complete example is listed\n",
    "below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt\n",
    "from math import log\n",
    "from math import exp\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# invert box-cox transform\n",
    "def boxcox_inverse(value, lam):\n",
    "    if lam == 0:\n",
    "        return exp(value)\n",
    "    return exp(log(lam * value + 1) / lam)\n",
    "\n",
    "\n",
    "# prepare data\n",
    "X = dataset.values\n",
    "X = X.astype(\"float32\")\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "# walk-forward validation\n",
    "history = [x for x in train]\n",
    "predictions = list()\n",
    "for i in range(len(test)):\n",
    "    # transform\n",
    "    transformed, lam = boxcox(history)\n",
    "    if lam < -5:\n",
    "        transformed, lam = history, 1\n",
    "    # predict\n",
    "    model = ARIMA(transformed, order=(0, 1, 2))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    # invert transformed prediction\n",
    "    yhat = boxcox_inverse(yhat, lam)\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = test[i]\n",
    "    history.append(obs)\n",
    "    print(\">Predicted=%.3f, Expected=%3.f\" % (yhat, obs))\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(test, predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be ignored for now. The final RMSE of the model on the transformed data was\n",
    "49.103. This is a smaller error than the ARIMA model on untransformed data, but only slightly,\n",
    "and it may or may not be statistically different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this model with the Box-Cox transform as the final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After models have been developed and a final model selected, it must be validated and finalized.\n",
    "Validation is an optional part of the process, but one that provides a last check to ensure we have not fooled or lied to ourselves. This section includes the following steps:\n",
    "\n",
    "- Finalize Model: Train and save the final model.\n",
    "- Make Prediction: Load the finalized model and make a prediction.\n",
    "- Validate Model: Load and validate the final model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizing the model involves fitting an ARIMA model on the entire dataset, in this case, on a\n",
    "transformed version of the entire dataset. Once fit, the model can be saved to file for later use.\n",
    "Because a Box-Cox transform is also performed on the data, we need to know the chosen lambda\n",
    "so that any predictions from the model can be converted back to the original, untransformed\n",
    "scale. The example below fits an ARIMA(0,1,2) model on the Box-Cox transform dataset and\n",
    "saves the whole fit object and the lambda value to file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "# monkey patch around bug in ARIMA class\n",
    "def __getnewargs__(self):\n",
    "    return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))\n",
    "\n",
    "\n",
    "ARIMA.__getnewargs__ = __getnewargs__\n",
    "\n",
    "\n",
    "# prepare data\n",
    "X = dataset.values\n",
    "X = X.astype(\"float32\")\n",
    "# transform data\n",
    "transformed, lam = boxcox(X)\n",
    "# fit model\n",
    "model = ARIMA(transformed, order=(0, 1, 2))\n",
    "model_fit = model.fit(disp=0)\n",
    "\n",
    "# save model\n",
    "model_fit.save(\"model.pkl\")\n",
    "numpy.save(\"model_lambda.npy\", [lam])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.pkl This is the ARIMAResult object from the call to ARIMA.fit().\n",
    "\n",
    "This includes the coefficients and all other internal data returned when fitting the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_lambda.npy This is the lambda value stored as a one-row, one-column NumPy\n",
    "array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural case may be to load the model and make a single forecast. This is relatively straight-forward and involves restoring the saved model and the lambda and calling the forecast()\n",
    "function. **The example below loads the model, makes a prediction for the next time step, inverses\n",
    "the Box-Cox transform, and prints the prediction**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# load the finalized model and make a prediction\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "from math import exp\n",
    "from math import log\n",
    "import numpy\n",
    "\n",
    "\n",
    "# invert box-cox transform\n",
    "def boxcox_inverse(value, lam):\n",
    "    if lam == 0:\n",
    "        return exp(value)\n",
    "    return exp(log(lam * value + 1) / lam)\n",
    "\n",
    "\n",
    "model_fit = ARIMAResults.load(\"model.pkl\")\n",
    "lam = numpy.load(\"model_lambda.npy\")\n",
    "yhat = model_fit.forecast()[0]\n",
    "yhat = boxcox_inverse(yhat, lam)\n",
    "\n",
    "print(\"Predicted: %.3f\" % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the prediction of about 452. If we peek inside validation.csv,\n",
    "we can see that the value on the first row for the next time period is 452. The model got it\n",
    "100% correct, which is very impressive (or lucky).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the model and use it in a pretend operational manner. In the test harness section,\n",
    "we saved the final 12 months of the original dataset in a separate file to validate the final model.\n",
    "We can load this validation.csv file now and use it see how well our model really is on unseen\n",
    "data. There are two ways we might proceed:\n",
    "\n",
    "- Load the model and use it to forecast the next 12 months. The forecast beyond the first\n",
    "  one or two months will quickly start to degrade in skill.\n",
    "- Load the model and use it in a rolling-forecast manner, updating the transform and model\n",
    "  for each time step. This is the preferred method as it is how one would use this model in\n",
    "  practice, as it would achieve the best performance.\n",
    "\n",
    "We will make predictions in a rolling-forecast\n",
    "manner. This means that we will step over lead times in the validation dataset and take the\n",
    "observations as an update to the history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'estadistica-avanzada-NMzyT9uv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/david/.local/share/virtualenvs/estadistica-avanzada-NMzyT9uv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# invert box-cox transform\n",
    "def boxcox_inverse(value, lam):\n",
    "    if lam == 0:\n",
    "        return exp(value)\n",
    "    return exp(log(lam * value + 1) / lam)\n",
    "\n",
    "\n",
    "# load and prepare datasets\n",
    "\n",
    "X = dataset.values.astype(\"float32\")\n",
    "history = [x for x in X]\n",
    "\n",
    "y = validation.values.astype(\"float32\")\n",
    "# load model\n",
    "model_fit = ARIMAResults.load(\"model.pkl\")\n",
    "lam = numpy.load(\"model_lambda.npy\")\n",
    "# make first prediction\n",
    "predictions = list()\n",
    "yhat = model_fit.forecast()[0]\n",
    "yhat = boxcox_inverse(yhat, lam)\n",
    "predictions.append(yhat)\n",
    "history.append(y[0])\n",
    "print(\">Predicted=%.3f, Expected=%3.f\" % (yhat, y[0]))\n",
    "# rolling forecasts\n",
    "for i in range(1, len(y)):\n",
    "    # transform\n",
    "    transformed, lam = boxcox(history)\n",
    "    if lam < -5:\n",
    "        transformed, lam = history, 1\n",
    "    # predict\n",
    "    model = ARIMA(transformed, order=(0, 1, 2))\n",
    "    model_fit = model.fit(disp=0)\n",
    "    yhat = model_fit.forecast()[0]\n",
    "    # invert transformed prediction\n",
    "    yhat = boxcox_inverse(yhat, lam)\n",
    "    predictions.append(yhat)\n",
    "    # observation\n",
    "    obs = y[i]\n",
    "    history.append(obs)\n",
    "    print(\">Predicted=%.3f, Expected=%3.f\" % (yhat, obs))\n",
    "# report performance\n",
    "rmse = sqrt(mean_squared_error(y, predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "pyplot.plot(y)\n",
    "pyplot.plot(predictions, color=\"red\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints each prediction and expected value for the time steps in the\n",
    "validation dataset. The final RMSE for the validation period is predicted at 53 robberies. This\n",
    "is not too different to the expected error of 49, but I would expect that it is also not too different\n",
    "from a simple persistence model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the predictions compared to the validation dataset is also provided. The forecast\n",
    "does have the characteristic of a persistence forecast. This does suggest that although this time\n",
    "series does have an obvious trend, it is still a reasonably difficult problem.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
